# AWS FUndementals 
#### Types of Data
1. Structured Data - -easily queriable,organized columns,cleanup already(psql,oracle,csv and execel if there area structured)
2. Unstructured Data - doesnt have a predefined schema,raw text files,videos,audio,emails
3. Semi Structured data - xml and jsons

#### Properties of Data 
1. Volume - size of data, 
2. Velocity - speed at which new data is generated collected procossesd(batch vs streaming)
3. variety  - types of data, strututed vs semi ,source of data ,format of data

### Data Warehouse vs Data Lake 

#### Data warehouse (Extract Trsanform and then load to Data warehouse)
A centralized repository optimized for analysis where data from different sources is stored in strutured format 
designed for analysis 
optimized for read heavy operations 

Examples : Amazon Redshift,Google Bigquery ,Azure SQL Data warehouse 

#### Data Lake (Extract Load and then transform when we need to )
do not preprocess just store all the data in lake house 

Example : Amazon s3,HDFS

Which to choose  : 
data warehouse : when you have strtured data and want to use ti for analytics 
data lakes : need raw data for machine learning 


### Data Lakehouse : Combingin Datawarehouse and Datalake

# Data Lineage
### Spline Agent
it store it in graph data base called Amazon Neptune


Schema Evolution:

Schema GLue REgistry has backward compability 
### Sage Maker


Data base optimizations : 
Adding indexes 
Paritioning 
Compression : use better file formats ,also compression (GZIP,LZOP also talk about these)

Data Sampling techniqies
1. Random Sampling 
2. Stratified Sampling 
3. Systemic Sampling (every thrid record )

Data Skewing 

temporal skew old data has less data and new data bassed on same partition could be huge

How do you partition :

1. Adaptive Partitioning 
2. Salting 
3. Regular Repartition (not recommended)
4. Sampling 
5. Custom parititiong 

## AWs S3
1. s3 bucket names are unique across globe 
Naming Conventions : 
no uppercase no underscores no ip must start with lower case  must not start with xn must not end with s3 s3alias
key is basciclly the full path of the file without the s3b bucekt name 
example : s3:<<bucketname>>/folder1/subfolder1/myfile.txt
here the key is /folder1/subfolder1/myfile.txt
value is the content of the file
max size is 5TB 
if each file is more than 5gb then use multi-part upload to upload files


Amazon s3 Security 
1. User based 
iam policies : which specific user should be allowed from IAM 
2. Resource Based :
bucket wide policies 
Object ACLs(Access Control Lists)
Bucket ACLs()
3. Encrpty objects on s3 using encryption keys 

S3 JSON Example :
there is this policy genertor in aws console we can use to generate policies


### S3 versioning 

Use to protect from unintended deletes and also we can roll back to a version 


this is on a bucket level

when ever we delete files on versionsing basially it just adds delete market to the file 

how to restore files of deleted files is you delete the delete marker

### S3 Replication 
also have to enable versioning in both source and target buckets
By default delete markers are not replicated by this can be changed in replication rule
also if you delete a source object it is not replicated in the target bucket 

has two things CRR(Cross region replication) and SRR(Same Region Replication)

### S3 Storage Classes
1. Amazon S3 Standard - General Purpose 
2. Amazon S3 Standard - Infrequent Access(IA)
3. Amazon S3 One Zone - Infrequent Access
4. Amazon S3 Glacier Instant Retrival 
5. Amazon S3 Glacier Flexible Retrival 
6. Amazon S3 Glacier Deep dive 
7. Amazon S3 Intelligent Tiering

Mainly depends on two things Durability and Availability
Durability : Highly Durable (99.9(11 times))
Availablility -  depends on storage classe

<<add print screen of s3 durablity and availability classe>>
